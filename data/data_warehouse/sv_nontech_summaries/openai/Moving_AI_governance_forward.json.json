{
    "unique_id": "15a91c6b-d64f-58b0-b00d-070638c31ed7",
    "title": "Moving AI governance forward",
    "summary": "AI-laboratorier som OpenAI har \u00e5tagit sig frivilliga \u00e5taganden f\u00f6r att st\u00e4rka s\u00e4kerheten, tryggheten och tillf\u00f6rlitligheten hos AI-teknologi och tj\u00e4nster. Dessa \u00e5taganden, som samordnas av Vita huset, \u00e4r ett viktigt steg f\u00f6r att fr\u00e4mja meningsfull och effektiv AI-styrning b\u00e5de i USA och runt om i v\u00e4rlden. \u00c5tagandena inkluderar bland annat intern och extern granskning av modeller och system f\u00f6r att identifiera risker och faror, samarbete och informationsdelning mellan f\u00f6retag och regeringar f\u00f6r att hantera s\u00e4kerhetsrisker, investeringar i cybers\u00e4kerhet och skydd av f\u00f6retagshemligheter, samt utveckling av mekanismer f\u00f6r att anv\u00e4ndare ska kunna avg\u00f6ra om ljud- eller bildinneh\u00e5ll \u00e4r genererat av AI. F\u00f6retagen \u00e5tar sig ocks\u00e5 att rapportera om modellers kapabiliteter, begr\u00e4nsningar och anv\u00e4ndningsomr\u00e5den samt att prioritera forskning om samh\u00e4llsrisker och att utveckla AI-system f\u00f6r att m\u00f6ta samh\u00e4llets st\u00f6rsta utmaningar.",
    "link": "https://openai.com/blog/moving-ai-governance-forward",
    "published": "2023-07-21"
}