{
    "unique_id": "39a72cb7-ff26-5be5-815d-2319c8e3f7c5",
    "title": "New method improves efficiency of 'vision transformer' AI systems",
    "summary": "Transformatorer \u00e4r bland de mest kraftfulla AI-modellerna. Till exempel anv\u00e4nder ChatGPT en AI som anv\u00e4nder transformerarkitektur, men inmatningarna som anv\u00e4nds f\u00f6r att tr\u00e4na den \u00e4r spr\u00e5k. ViTs \u00e4r transformerbaserade AI som tr\u00e4nas med visuella inmatningar. Till exempel kan ViTs anv\u00e4ndas f\u00f6r att uppt\u00e4cka och kategorisera objekt i en bild, som att identifiera alla bilar eller alla fotg\u00e4ngare i en bild.\nViTs st\u00e5r dock inf\u00f6r tv\u00e5 utmaningar.\nF\u00f6r det f\u00f6rsta \u00e4r transformermodeller mycket komplexa. I f\u00f6rh\u00e5llande till m\u00e4ngden data som matas in i AI kr\u00e4ver transformermodeller en betydande m\u00e4ngd ber\u00e4kningskraft och anv\u00e4nder en stor m\u00e4ngd minne. Detta \u00e4r s\u00e4rskilt problematiskt f\u00f6r ViTs, eftersom bilder inneh\u00e5ller s\u00e5 mycket data.\nF\u00f6r det andra \u00e4r det sv\u00e5rt f\u00f6r anv\u00e4ndare att f\u00f6rst\u00e5 exakt hur ViTs fattar beslut. Till exempel kan du ha tr\u00e4nat en ViT att identifiera hundar i en bild. Men det \u00e4r inte helt klart hur ViT best\u00e4mmer vad som \u00e4r en hund och vad som inte \u00e4r det. Beroende p\u00e5 till\u00e4mpningen kan f\u00f6rst\u00e5else f\u00f6r ViTs beslutsfattande process, \u00e4ven k\u00e4nd som dess modelltolkningsf\u00f6rm\u00e5ga, vara mycket viktig.\nDen nya ViT-metodiken, kallad \"Patch-to-Cluster attention\" (PaCa), tar itu med b\u00e5da utmaningarna.\n\"Vi hanterar utmaningen relaterad till ber\u00e4knings- och minneskrav genom att anv\u00e4nda klusteringsmetoder, vilket g\u00f6r att transformerarkitekturen b\u00e4ttre kan identifiera och fokusera p\u00e5 objekt i en bild\", s\u00e4ger Tianfu Wu, korresponderande f\u00f6rfattare till en artikel om arbetet och bitr\u00e4dande professor i elektroteknik och datorteknik vid North Carolina State University. \"Klustrering inneb\u00e4r att AI: n grupperar avsnitt av bilden tillsammans, baserat p\u00e5 likheter den hittar i bilddata. Detta minskar betydligt ber\u00e4kningskraven p\u00e5 systemet. Innan klustrering \u00e4r ber\u00e4kningskraven f\u00f6r en ViT kvadratiska. Till exempel, om systemet delar upp en bild i 100 mindre enheter, skulle det beh\u00f6va j\u00e4mf\u00f6ra alla 100 enheter med varandra - vilket skulle vara 10 000 komplexa funktioner.\n\"Genom klustrering kan vi g\u00f6ra detta till en linj\u00e4r process, d\u00e4r varje mindre enhet bara beh\u00f6ver j\u00e4mf\u00f6ras med ett f\u00f6rbest\u00e4mt antal kluster. S\u00e4g att du talar om f\u00f6r systemet att etablera 10 kluster; det skulle bara vara 1 000 komplexa funktioner\", s\u00e4ger Wu.\n\"Klustrering g\u00f6r det ocks\u00e5 m\u00f6jligt f\u00f6r oss att hantera modelltolkningsf\u00f6rm\u00e5gan, eftersom vi kan titta p\u00e5 hur den skapade klustren fr\u00e5n f\u00f6rsta b\u00f6rjan. Vilka funktioner ans\u00e5g den vara viktiga n\u00e4r den grupperade dessa datasektioner tillsammans? Och eftersom AI bara skapar ett litet antal kluster kan vi titta p\u00e5 dem ganska enkelt.\"\nForskarna genomf\u00f6rde omfattande tester av PaCa och j\u00e4mf\u00f6rde det med tv\u00e5 toppmoderna ViTs som kallas SWin och PVT.\n\"Vi fann att PaCa \u00f6vertr\u00e4ffade SWin och PVT p\u00e5 alla s\u00e4tt\", s\u00e4ger Wu. \"PaCa var b\u00e4ttre p\u00e5 att klassificera objekt i bilder, b\u00e4ttre p\u00e5 att identifiera objekt i bilder och b\u00e4ttre p\u00e5 segmentering - i princip att markera gr\u00e4nserna f\u00f6r objekt i bilder. Den var ocks\u00e5 mer effektiv, vilket inneb\u00e4r att den kunde utf\u00f6ra dessa uppgifter snabbare \u00e4n de andra ViTs.\n\"N\u00e4sta steg f\u00f6r oss \u00e4r att skala upp PaCa genom att tr\u00e4na p\u00e5 st\u00f6rre grundl\u00e4ggande datam\u00e4ngder.\"\nArtikeln \"PaCa-ViT: Learning Patch-to-Cluster Attention in Vision Transformers\" kommer att presenteras vid IEEE/CVF Conference on Computer Vision and Pattern Recognition, som h\u00e5lls den 18-22 juni i Vancouver, Kanada. F\u00f6rstaf\u00f6rfattare till artikeln \u00e4r Ryan Grainger, doktorand vid NC State. Artikeln f\u00f6rfattades ocks\u00e5 av Thomas Paniagua, doktorand vid NC State; Xi Song, oberoende forskare; och Naresh Cuntoor och Mun Wai Lee fr\u00e5n BlueHalo.\nArbetet utf\u00f6rdes med st\u00f6d fr\u00e5n Office of the Director of National Intelligence, under kontraktsnummer 2021-21040700003; U.S. Army Research Office, under bidragen W911NF1810295 och W911NF2210010; och National Science Foundation, under bidragen 1909644, 1822477, 2024688 och 2013451.",
    "link": "https://www.sciencedaily.com/releases/2023/06/230601160053.htm",
    "published": "2023-06-01"
}