{
    "unique_id": "98f0a8ee-00b5-5d7e-be05-d1581c2b5860",
    "title": "How machine-learning models can amplify inequities in medical diagnosis and treatment",
    "summary": "Researchers at MIT have explored the biases that can arise in machine learning models used in healthcare. The study focused on \"subpopulation shifts,\" which are differences in how well the models perform for different groups. The researchers identified four types of shifts: spurious correlations, attribute imbalance, class imbalance, and attribute generalization. They found that improving the classifier layer of the neural network reduced spurious correlations and class imbalance, while improving the encoder layer reduced attribute imbalance. However, they were unable to address attribute generalization. The researchers also discovered that boosting worst-group accuracy decreased worst-case precision, highlighting the need to balance accuracy and precision in medical diagnostics. The ultimate goal is to achieve fairness in healthcare for all populations, but more understanding of the sources of unfairness is needed.",
    "link": "https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817",
    "published": "2023-08-17"
}