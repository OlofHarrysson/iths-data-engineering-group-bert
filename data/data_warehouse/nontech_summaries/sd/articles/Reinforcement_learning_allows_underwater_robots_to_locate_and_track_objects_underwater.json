{
    "unique_id": "234c5b42-6d60-5065-af8d-1d72d2ab1e4d",
    "title": "Reinforcement learning allows underwater robots to locate and track objects underwater",
    "summary": "Underwater robotics is becoming increasingly important for exploring the oceans and gathering data. These robots can dive to depths of up to 4,000 meters and provide valuable information that complements satellite data. One area where underwater robots are making a difference is in studying small-scale phenomena like CO2 capture by marine organisms, which helps regulate climate change.\n\nA recent study has shown that reinforcement learning, a technique commonly used in control and robotics, can be applied to underwater robots. This allows them to learn the best actions to take at any given time to achieve a specific goal. In some cases, this learning method even outperforms traditional analytical approaches.\n\nThe researchers used range acoustic techniques to estimate the position of objects underwater. However, the accuracy of these measurements depends on where they are taken. By applying reinforcement learning, the robots can identify the best points to take measurements and determine the optimal trajectory to locate and track objects.\n\nThe neural networks used in this study were trained using the powerful supercomputers at the Barcelona Supercomputing Center. Once trained, the algorithms were tested on different autonomous vehicles, including the AUV Sparus II.\n\nThe researchers are now looking into applying these algorithms to more complex missions, such as using multiple vehicles to locate objects or detect fronts and thermoclines. This research was made possible by a Marie Curie Individual Fellowship and funding from the Ministry of Science and Innovation of the Government of Spain.\n\nOverall, this study demonstrates the potential of using reinforcement learning in underwater robotics to improve our understanding of the oceans and monitor oceanographic instruments in real-time.",
    "link": "https://www.sciencedaily.com/releases/2023/07/230728113428.htm",
    "published": "2023-07-28"
}