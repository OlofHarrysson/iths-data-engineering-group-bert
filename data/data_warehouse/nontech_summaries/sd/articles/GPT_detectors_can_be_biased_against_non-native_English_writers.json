{
    "unique_id": "1af3dc52-6eac-5251-b1b1-661d57589c16",
    "title": "GPT detectors can be biased against non-native English writers",
    "summary": "A recent study conducted by researchers at Stanford University has raised concerns about the reliability and effectiveness of AI detectors used to identify AI-generated text. These detectors are increasingly being used by educators to screen students' assignments, but the study found that they incorrectly labeled more than half of the essays written by non-native English speakers as AI-generated. In contrast, the detectors were able to correctly classify essays written by eighth-grade students as human-generated. The detectors work by evaluating text perplexity, which measures the surprisingness of word choice in an essay. Non-native English writers who use simpler word choices are more likely to be flagged as using AI. The researchers also found that the detectors could be easily fooled by editing the text to include more sophisticated language. The study's senior author recommends caution in using these detectors, as they can have significant consequences if used to review job applications, college entrance essays, or high school assignments. The detectors may also have implications beyond education, as search engines like Google devalue AI-generated content, potentially silencing non-native English writers. The researchers suggest that further enhancements and evaluations of these detectors are needed, including training them with more diverse types of writing.",
    "link": "https://www.sciencedaily.com/releases/2023/07/230710113921.htm",
    "published": "2023-07-10"
}