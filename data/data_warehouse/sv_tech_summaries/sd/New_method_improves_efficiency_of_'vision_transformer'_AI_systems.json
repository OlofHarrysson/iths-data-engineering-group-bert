{
    "unique_id": "39a72cb7-ff26-5be5-815d-2319c8e3f7c5",
    "title": "New method improves efficiency of 'vision transformer' AI systems",
    "summary": "Transformer-modeller \u00e4r kraftfulla AI-modeller, men Visual Transformers (ViTs) st\u00e5r inf\u00f6r utmaningar. De kr\u00e4ver mycket ber\u00e4kningskraft och minne p\u00e5 grund av bildernas stora datam\u00e4ngd. Dessutom \u00e4r det sv\u00e5rt att f\u00f6rst\u00e5 hur ViTs fattar beslut. En ny metod, kallad \"Patch-to-Cluster attention\" (PaCa), l\u00f6ser dessa utmaningar genom att anv\u00e4nda klustermetoder f\u00f6r att minska ber\u00e4kningskraven och f\u00f6rb\u00e4ttra modellens tolkningsbarhet. PaCa \u00f6vertr\u00e4ffade andra ViTs i tester och n\u00e4sta steg \u00e4r att tr\u00e4na p\u00e5 st\u00f6rre datam\u00e4ngder. Forskningen st\u00f6ddes av flera organisationer, inklusive National Science Foundation och U.S. Army Research Office.",
    "link": "https://www.sciencedaily.com/releases/2023/06/230601160053.htm",
    "published": "2023-06-01"
}